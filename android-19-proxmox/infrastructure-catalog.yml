---
# Proxmox Infrastructure Catalog - Source of Truth for IDs and IPs
# This catalog defines all infrastructure managed by Proxmox (containers and VMs)
# All Proxmox roles/playbooks should reference this catalog for ID and IP assignments
#
# Network Strategy (see docs/adr/002-homelab-network-strategy.md):
# - Proxmox host: 192.168.0.19
# - Containers: .20-.99 (ID matches IP last octet)
# - VMs: .100-.199 (ID matches IP last octet)
# - DHCP pool: .200-.249
#
# To add a new service:
# 1. Choose appropriate IP range based on service type
# 2. Pick unused ID matching IP last octet if possible
# 3. Add entry with type: "container" or "vm"
# 4. Set cloud_init flag:
#    - true: VM uses cloud image with cloud-init support (automated)
#    - false: VM uses ISO requiring manual installation
# 5. Update role to use: catalog.services[ID]

# Services (both containers and VMs - unified to prevent ID conflicts)
# All services are provisioned by Terraform
services:
  125:
    name: "adguard"
    type: "container"
    ip: "192.168.0.25"
    description: "AdGuard Home DNS server"
    template: "debian-12-standard_12.12-1_amd64.tar.zst"
    resources:
      cores: 2
      memory: 1024
      disk: 16
    storage: "vm-storage"

  130:
    name: "test-nginx"
    type: "container"
    ip: "192.168.0.30"
    description: "Test container for Terraform provisioning"
    template: "debian-12-standard_12.12-1_amd64.tar.zst"
    resources:
      cores: 1
      memory: 512
      disk: 8
    storage: "vm-storage"

  101:
    name: "omarchy"
    type: "vm"
    ip: "192.168.0.101"
    description: "Omarchy development workstation (Arch Linux + Hyprland)"
    iso: "omarchy-3.0.2.iso"  # Boot from Omarchy ISO
    cloud_init: false     # ISO does not support cloud-init (manual installation required)
    agent: true           # Enable QEMU guest agent (install after OS setup)
    onboot: false         # Manual start (development workstation)
    resources:
      cores: 16
      memory: 32768
      disk: 250  # Increased for development environment
    storage: "vm-storage"

  103:
    name: "ubuntu-desktop-dev"
    type: "vm"
    ip: "192.168.0.103"
    description: "Ubuntu Desktop clean master template (Ubuntu 24.04 + Omakub)"
    template_vm_id: 103  # Self-reference for clarity or used as clone source
    cloud_init: true
    agent: true
    onboot: false
    resources:
      cores: 32
      memory: 38912
      disk: 150
    storage: "vm-storage"

  106:
    name: "vm-ubuntu-desktop-openclaw"
    type: "vm"
    ip: "192.168.0.106"
    description: "OpenClaw game engine development workstation"
    template_vm_id: 103
    cloud_init: true
    agent: true
    onboot: false
    resources:
      cores: 8
      memory: 8192
      disk: 150
    storage: "vm-storage"

  140:
    name: "vm-llm-aimachine"
    type: "vm"
    ip: "192.168.0.140"
    description: "GPU-accelerated Ubuntu Server VM for AI/LLM workloads (vLLM, Ollama) with RTX 5060Ti passthrough"
    template_vm_id: 9000  # Ubuntu 24.04 cloud image template
    cloud_init: true      # Automated setup with cloud-init
    cloud_init_user: "ubuntu"  # Default user created by cloud-init
    cloud_init_password: "ubuntu"  # Initial password (will require change on first login)
    agent: true           # QEMU guest agent enabled
    onboot: true          # Auto-start on boot (AI workload server)
    gpu_passthrough:
      enabled: false      # GPU passthrough added via Ansible AFTER VM creation (API limitation when cloning)
      device_id: "0000:02:00"  # PCIe address for RTX 5060Ti (verified: 02:00.0)
      hostpci: "hostpci0"      # Proxmox hostpci identifier
    resources:
      cores: 32
      memory: 32768  # 32GB in MB
      disk: 500
    storage: "vm-storage"

  141:
    name: "vm-llm-aimachine-testing"
    type: "vm"
    ip: "192.168.0.141"
    description: "Testing instance - GPU-accelerated Ubuntu Server VM for AI/LLM workloads (vLLM, Ollama) with RTX 5060Ti passthrough"
    template_vm_id: 9000  # Ubuntu 24.04 cloud image template
    cloud_init: true      # Automated setup with cloud-init
    cloud_init_user: "ubuntu"  # Default user created by cloud-init
    cloud_init_password: "ubuntu"  # Initial password
    agent: true           # QEMU guest agent enabled
    onboot: false         # Manual start (testing VM)
    gpu_passthrough:
      enabled: false      # GPU passthrough added via Ansible AFTER VM creation (API limitation when cloning)
      device_id: "0000:02:00"  # Same GPU - tests time-sharing capability
      hostpci: "hostpci0"      # Proxmox hostpci identifier
    resources:
      cores: 16           # Half resources for testing
      memory: 25600       # 25GB in MB
      disk: 250           # Half disk space for testing
    storage: "vm-storage"

  160:
    name: "vm-coolify-platform"
    type: "vm"
    ip: "192.168.0.160"
    description: "Coolify Platform - Self-hosted PaaS for application deployment with automatic SSL and GitHub integration"
    template_vm_id: 9000  # Ubuntu 24.04 cloud image template
    cloud_init: true      # Automated setup with cloud-init
    cloud_init_user: "ubuntu"  # Default user created by cloud-init
    cloud_init_password: "ubuntu"  # Initial password (will require change on first login)
    agent: true           # QEMU guest agent enabled
    onboot: true          # Auto-start on boot (platform service)
    resources:
      cores: 8
      memory: 16384       # 16GB in MB
      disk: 200
    storage: "vm-storage"

  126:
    name: "monitoring"
    type: "container"
    ip: "192.168.0.26"
    description: "Observability stack (Prometheus, Grafana, Node Exporter) for hardware monitoring"
    template: "debian-12-standard_12.12-1_amd64.tar.zst"
    resources:
      cores: 2
      memory: 4096
      disk: 20
    storage: "vm-storage"



# Proxmox Host Configuration
proxmox:
  ip: "192.168.0.19"
  node_name: "proxmox"
  api_port: 8006

# Network Configuration
network:
  subnet: "192.168.0.0/24"
  gateway: "192.168.0.1"
  dns: "192.168.0.25"  # AdGuard Home DNS server

  # IP Range Allocation Strategy (for Proxmox-managed infrastructure)
  ranges:
    containers: "192.168.0.20-99"        # LXC containers
    virtual_machines: "192.168.0.100-199" # QEMU VMs
    dhcp_pool: "192.168.0.200-249"       # Dynamic allocation for VMs
    reserved: "192.168.0.250-254"        # Future use